{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Wells\\Anaconda3\\envs\\DLCVMarathon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 2.1098 - accuracy: 0.3463\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.9417 - accuracy: 0.3389\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.9590 - accuracy: 0.3294\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.8141 - accuracy: 0.3827\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.7361 - accuracy: 0.4209\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.7656 - accuracy: 0.4139\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.7656 - accuracy: 0.4125\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.7171 - accuracy: 0.4339\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.6701 - accuracy: 0.4520\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.9473 - accuracy: 0.3510\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 10s 210us/step - loss: 1.8288 - accuracy: 0.3622\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 10s 210us/step - loss: 1.7277 - accuracy: 0.4374\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.8942 - accuracy: 0.3327\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 10s 210us/step - loss: 1.7595 - accuracy: 0.4056\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.7198 - accuracy: 0.4129\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.6445 - accuracy: 0.4599\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 10s 210us/step - loss: 1.6259 - accuracy: 0.4536\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.7478 - accuracy: 0.4135\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.6155 - accuracy: 0.4651\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.5953 - accuracy: 0.4666\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.5566 - accuracy: 0.4932\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.5443 - accuracy: 0.4966\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.5689 - accuracy: 0.4963\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.5030 - accuracy: 0.5078\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.5052 - accuracy: 0.5123\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.6009 - accuracy: 0.4719\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.4917 - accuracy: 0.5119\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.4502 - accuracy: 0.5290\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.4302 - accuracy: 0.5356s\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.5699 - accuracy: 0.4919\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.6360 - accuracy: 0.4529\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.5369 - accuracy: 0.4897\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.5003 - accuracy: 0.4966\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.4491 - accuracy: 0.5249\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.5093 - accuracy: 0.5070\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.4770 - accuracy: 0.5272\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.7014 - accuracy: 0.4408\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.5401 - accuracy: 0.4972\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.5016 - accuracy: 0.5059\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.4604 - accuracy: 0.5162\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.4800 - accuracy: 0.5140\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.4620 - accuracy: 0.5146\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.3862 - accuracy: 0.5475\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.3330 - accuracy: 0.5632\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.3288 - accuracy: 0.5646\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.4601 - accuracy: 0.5404\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.9102 - accuracy: 0.3868\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.5936 - accuracy: 0.4600\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.4987 - accuracy: 0.5052\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.4352 - accuracy: 0.5299\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.4483 - accuracy: 0.5238\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.3497 - accuracy: 0.5576\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.4852 - accuracy: 0.4996\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.4029 - accuracy: 0.5353\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.4203 - accuracy: 0.5310\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.3426 - accuracy: 0.5623\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.3735 - accuracy: 0.5516\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.3355 - accuracy: 0.5646\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 10s 210us/step - loss: 1.3489 - accuracy: 0.5611\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.3026 - accuracy: 0.5762\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.3412 - accuracy: 0.5712\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.3270 - accuracy: 0.5740\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.3159 - accuracy: 0.5744\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.3114 - accuracy: 0.5787\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.5612 - accuracy: 0.4952\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.5459 - accuracy: 0.4961\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.6285 - accuracy: 0.4913\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 1.6200 - accuracy: 0.4502\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.5245 - accuracy: 0.4822\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.4399 - accuracy: 0.5097\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3893 - accuracy: 0.5292\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.3459 - accuracy: 0.5521\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 1.3300 - accuracy: 0.5643\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.5579 - accuracy: 0.5211\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 1.3252 - accuracy: 0.5714\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 1.3308 - accuracy: 0.5682\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.5254 - accuracy: 0.5018\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.4405 - accuracy: 0.5245\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.3532 - accuracy: 0.5521\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.3625 - accuracy: 0.5516\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.2921 - accuracy: 0.5758\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.2909 - accuracy: 0.5783\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.2197 - accuracy: 0.6023\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.2442 - accuracy: 0.5972\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.5295 - accuracy: 0.5111\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.3562 - accuracy: 0.5411\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.2612 - accuracy: 0.5852\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.3561 - accuracy: 0.5562\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.2445 - accuracy: 0.5911\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.2277 - accuracy: 0.5999\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.2084 - accuracy: 0.6080\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.1986 - accuracy: 0.6151\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 1.2556 - accuracy: 0.5959\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.1857 - accuracy: 0.6122\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.2096 - accuracy: 0.6052\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.2288 - accuracy: 0.6016\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 1.4066 - accuracy: 0.5414\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.4106 - accuracy: 0.5551\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 1.3004 - accuracy: 0.5738\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.2656 - accuracy: 0.5876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1aea0639e08>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same',input_shape=(32,32,3)))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same',input_shape=(32,32,3)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(output_dim=100, activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10, activation='relu'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 438.26526,    0.     , 1609.9327 , 1290.2622 ,  828.42786,\n",
       "         524.5265 ,  418.1821 ,    0.     ,    0.     ,    0.     ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
